[
  {
    'job_id': '8tccf',
    'type': '1',
    'name': '115å¹´ç ”ç™¼æ›¿ä»£å½¹ - è»Ÿ/éŸŒé«”å·¥ç¨‹å¸«',
    'appear_date': '20260112',
    'apply_num': 32,
    'apply_text': 'å¤§æ–¼30äººæ‡‰å¾µ',
    'company_name': 'æ—ºå®é›»å­è‚¡ä»½æœ‰é™å…¬å¸',
    'company_addr': 'æ–°ç«¹å¸‚ åŠ›è¡Œè·¯16è™Ÿ',
    'job_url': 'https://www.104.com.tw/job/8tccf?jobsource=hotjob_chr',
    'job_analyze_url': 'https://www.104.com.tw/jobs/apply/analysis/8tccf?channel=104rpt&jobsource=hotjob_chr',
    'job_company_url': 'https://www.104.com.tw/company/a5hi0dc?jobsource=hotjob_chr',
    'lon': '121.0251782',
    'lat': '24.7674628',
    'education': 'ç¢©å£«',
    'period': 'ç¶“æ­·ä¸æ‹˜',
    'salary': 'å¾…é‡é¢è­°',
    'salary_high': 0,
    'salary_low': 0,
    'tags': {
      'zone': {
        'desc': 'ä¸Šå¸‚ä¸Šæ«ƒ',
        'param': 16
      },
      'emp': {
        'desc': 'å“¡å·¥3900äºº',
        'param': '8'
      }
    }
  },
  {
    'job_id': '8x2tr',
    'type': '0',
    'name': 'Pythonå·¥ç¨‹å¸«(ç«¹ç§‘)',
    'appear_date': '20260107',
    'apply_num': 4,
    'apply_text': '0~5äººæ‡‰å¾µ',
    'company_name': 'å‰é€²åœ‹éš›è‚¡ä»½æœ‰é™å…¬å¸',
    'company_addr': 'æ–°ç«¹å¸‚ ',
    'job_url': 'https://www.104.com.tw/job/8x2tr?jobsource=2018indexpoc',
    'job_analyze_url': 'https://www.104.com.tw/jobs/apply/analysis/8x2tr?channel=104rpt&jobsource=apply_analyze',
    'job_company_url': 'https://www.104.com.tw/company/7hlkrgw?jobsource=2018indexpoc',
    'lon': '120.9674798',
    'lat': '24.8138287',
    'education': 'å­¸æ­·ä¸æ‹˜',
    'period': '2å¹´ä»¥ä¸Š',
    'salary': 'å¾…é‡é¢è­°',
    'salary_high': 0,
    'salary_low': 0,
    'tags': {
      'emp': {
        'desc': 'å“¡å·¥80äºº',
        'param': '5'
      }
    }
  },
  {
    'job_id': '8x2u8',
    'type': '0',
    'name': 'è³‡æ–™å·¥ç¨‹å¸«(ç«¹ç§‘)',
    'appear_date': '20260107',
    'apply_num': 3,
    'apply_text': '0~5äººæ‡‰å¾µ',
    'company_name': 'å‰é€²åœ‹éš›è‚¡ä»½æœ‰é™å…¬å¸',
    'company_addr': 'æ–°ç«¹å¸‚ ',
    'job_url': 'https://www.104.com.tw/job/8x2u8?jobsource=2018indexpoc',
    'job_analyze_url': 'https://www.104.com.tw/jobs/apply/analysis/8x2u8?channel=104rpt&jobsource=apply_analyze',
    'job_company_url': 'https://www.104.com.tw/company/7hlkrgw?jobsource=2018indexpoc',
    'lon': '120.9674798',
    'lat': '24.8138287',
    'education': 'å­¸æ­·ä¸æ‹˜',
    'period': '2å¹´ä»¥ä¸Š',
    'salary': 'å¾…é‡é¢è­°',
    'salary_high': 0,
    'salary_low': 0,
    'tags': {
      'emp': {
        'desc': 'å“¡å·¥80äºº',
        'param': '5'
      }
    }
  },
  {
    'job_id': '775wh',
    'type': '2',
    'name': 'ICC_Data Engineer',
    'appear_date': '20251127',
    'apply_num': 3,
    'apply_text': '0~5äººæ‡‰å¾µ',
    'company_name': 'Zyxel Networks_å…†å‹¤ç§‘æŠ€è‚¡ä»½æœ‰é™å…¬å¸(åˆå‹¤é›†åœ˜)',
    'company_addr': 'æ–°ç«¹å¸‚ æ–°ç«¹ç§‘å­¸åœ’å€å·¥æ¥­æ±ä¹è·¯2è™Ÿ/æ–°åŒ—å¸‚æ–°åº—å€åŒ—æ–°è·¯3æ®µ225è™Ÿ11æ¨“',
    'job_url': 'https://www.104.com.tw/job/775wh?jobsource=2018indexpoc',
    'job_analyze_url': 'https://www.104.com.tw/jobs/apply/analysis/775wh?channel=104rpt&jobsource=apply_analyze',
    'job_company_url': 'https://www.104.com.tw/company/1a2x6bli45?jobsource=2018indexpoc',
    'lon': '121.0084919',
    'lat': '24.7732416',
    'education': 'ç¢©å£«',
    'period': '1å¹´ä»¥ä¸Š',
    'salary': 'å¾…é‡é¢è­°',
    'salary_high': 0,
    'salary_low': 0,
    'tags': {
      'emp': {
        'desc': 'å“¡å·¥400äºº',
        'param': '7'
      }
    }
  },
  {
    'job_id': 'fkx5',
    'type': '0',
    'name': 'CAD  Engineer',
    'appear_date': '20251128',
    'apply_num': 2,
    'apply_text': '0~5äººæ‡‰å¾µ',
    'company_name': 'æ™ºæˆé›»å­è‚¡ä»½æœ‰é™å…¬å¸',
    'company_addr': 'æ–°ç«¹å¸‚ ç§‘å­¸å·¥æ¥­åœ’å€åŠ›è¡Œ6è·¯6è™Ÿ8æ¨“',
    'job_url': 'https://www.104.com.tw/job/fkx5?jobsource=2018indexpoc',
    'job_analyze_url': 'https://www.104.com.tw/jobs/apply/analysis/fkx5?channel=104rpt&jobsource=apply_analyze',
    'job_company_url': 'https://www.104.com.tw/company/5wzol4o?jobsource=2018indexpoc',
    'lon': '121.01464033126831',
    'lat': '24.77346735708958',
    'education': 'å¤§å­¸',
    'period': 'ç¶“æ­·ä¸æ‹˜',
    'salary': 'å¾…é‡é¢è­°',
    'salary_high': 0,
    'salary_low': 0,
    'tags': [
      
    ]
  },
  {
    'job_id': '89suk',
    'type': '2',
    'name': 'åŠ é€Ÿå™¨æ§åˆ¶ç³»çµ±ç ”ç™¼å·¥ç¨‹äººå“¡',
    'appear_date': '20260106',
    'apply_num': 2,
    'apply_text': '0~5äººæ‡‰å¾µ',
    'company_name': 'è²¡åœ˜æ³•äººåœ‹å®¶åŒæ­¥è¼»å°„ç ”ç©¶ä¸­å¿ƒ',
    'company_addr': 'æ–°ç«¹å¸‚ æ–°ç«¹ç§‘å­¸åœ’å€æ–°å®‰è·¯101è™Ÿ',
    'job_url': 'https://www.104.com.tw/job/89suk?jobsource=2018indexpoc',
    'job_analyze_url': 'https://www.104.com.tw/jobs/apply/analysis/89suk?channel=104rpt&jobsource=apply_analyze',
    'job_company_url': 'https://www.104.com.tw/company/2kmqv0o?jobsource=2018indexpoc',
    'lon': '120.993378',
    'lat': '24.781086',
    'education': 'ç¢©å£«',
    'period': 'ç¶“æ­·ä¸æ‹˜',
    'salary': 'æœˆè–ª60,000å…ƒä»¥ä¸Š',
    'salary_high': 60000,
    'salary_low': 9999999,
    'tags': {
      'emp': {
        'desc': 'å“¡å·¥450äºº',
        'param': '7'
      }
    }
  },
  {
    'job_id': '8weex',
    'type': '0',
    'name': 'éŸŒé«”å·¥ç¨‹å¸«',
    'appear_date': '20251229',
    'apply_num': 2,
    'apply_text': '0~5äººæ‡‰å¾µ',
    'company_name': 'å°ç£æ™ºæ…§æ„Ÿæ¸¬è‚¡ä»½æœ‰é™å…¬å¸',
    'company_addr': 'æ–°ç«¹å¸‚ åŠ›è¡Œä¸€è·¯1è™ŸçŸ½å°ç ”ç™¼ä¸­å¿ƒ',
    'job_url': 'https://www.104.com.tw/job/8weex?jobsource=2018indexpoc',
    'job_analyze_url': 'https://www.104.com.tw/jobs/apply/analysis/8weex?channel=104rpt&jobsource=apply_analyze',
    'job_company_url': 'https://www.104.com.tw/company/1a2x6bnlm1?jobsource=2018indexpoc',
    'lon': '121.0173543',
    'lat': '24.7740422',
    'education': 'å°ˆç§‘',
    'period': '1å¹´ä»¥ä¸Š',
    'salary': 'æœˆè–ª55,000~80,000å…ƒ',
    'salary_high': 55000,
    'salary_low': 80000,
    'tags': {
      'emp': {
        'desc': 'å“¡å·¥3äºº',
        'param': '1'
      }
    }
  },
  {
    'job_id': '8mt8q',
    'type': '0',
    'name': 'ç ”ç™¼å·¥ç¨‹å¸«',
    'appear_date': '20250509',
    'apply_num': 3,
    'apply_text': '0~5äººæ‡‰å¾µ',
    'company_name': 'åšæ¢­æ™ºèƒ½ç§‘æŠ€è‚¡ä»½æœ‰é™å…¬å¸',
    'company_addr': 'æ–°ç«¹å¸‚ åŠ›è¡Œä¸€è·¯1è™Ÿ1æ¨“A2-A01å®¤',
    'job_url': 'https://www.104.com.tw/job/8mt8q?jobsource=2018indexpoc',
    'job_analyze_url': 'https://www.104.com.tw/jobs/apply/analysis/8mt8q?channel=104rpt&jobsource=apply_analyze',
    'job_company_url': 'https://www.104.com.tw/company/1a2x6bnaku?jobsource=2018indexpoc',
    'lon': '121.0164719',
    'lat': '24.7716935',
    'education': 'å¤§å­¸',
    'period': 'ç¶“æ­·ä¸æ‹˜',
    'salary': 'å¾…é‡é¢è­°',
    'salary_high': 0,
    'salary_low': 0,
    'tags': [
      
    ]
  },
  {
    'job_id': '8rwr0',
    'type': '0',
    'name': 'ã€ç«¹ç§‘/ ç«¹åŒ—/ å…§æ¹–ã€‘è»Ÿé«”/ ç¡¬é«”æ¸¬è©¦å·¥ç¨‹å¸«ï½œæ´¾é§è¯ç™¼ç§‘',
    'appear_date': '20260109',
    'apply_num': 5,
    'apply_text': '0~5äººæ‡‰å¾µ',
    'company_name': 'å®ç¢å‰µé”è‚¡ä»½æœ‰é™å…¬å¸',
    'company_addr': 'æ–°ç«¹å¸‚ ',
    'job_url': 'https://www.104.com.tw/job/8rwr0?jobsource=2018indexpoc',
    'job_analyze_url': 'https://www.104.com.tw/jobs/apply/analysis/8rwr0?channel=104rpt&jobsource=apply_analyze',
    'job_company_url': 'https://www.104.com.tw/company/1a2x6bmt9z?jobsource=2018indexpoc',
    'lon': '120.9674798',
    'lat': '24.8138287',
    'education': 'å°ˆç§‘',
    'period': 'ç¶“æ­·ä¸æ‹˜',
    'salary': 'æœˆè–ª35,000å…ƒä»¥ä¸Š',
    'salary_high': 35000,
    'salary_low': 9999999,
    'tags': {
      'emp': {
        'desc': 'å“¡å·¥600äºº',
        'param': '8'
      }
    }
  },
  {
    'job_id': '8v6pl',
    'type': '0',
    'name': 'æ–°ç«¹å¸‚ï½œã€ç¾å•†ï½œå…¨çƒæ ¸å¿ƒè™•ç†å™¨ä¹‹é ˜å°å» å•†ã€‘è»Ÿ/ç¡¬é«”æ¸¬è©¦åŠ©ç†å·¥ç¨‹å¸«ï½œä¿éšœ14å€‹æœˆHCS-1801',
    'appear_date': '20260106',
    'apply_num': 1,
    'apply_text': '0~5äººæ‡‰å¾µ',
    'company_name': 'è—ç‚äººäº‹é¡§å•è‚¡ä»½æœ‰é™å…¬å¸',
    'company_addr': 'æ–°ç«¹å¸‚ ',
    'job_url': 'https://www.104.com.tw/job/8v6pl?jobsource=2018indexpoc',
    'job_analyze_url': 'https://www.104.com.tw/jobs/apply/analysis/8v6pl?channel=104rpt&jobsource=apply_analyze',
    'job_company_url': 'https://www.104.com.tw/company/1303ngy0?jobsource=2018indexpoc',
    'lon': '120.9674798',
    'lat': '24.8138287',
    'education': 'å¤§å­¸',
    'period': 'ç¶“æ­·ä¸æ‹˜',
    'salary': 'æœˆè–ª40,000å…ƒä»¥ä¸Š',
    'salary_high': 40000,
    'salary_low': 9999999,
    'tags': [
      
    ]
  }
]









import pandas as pd
import os
import requests
from datetime import datetime

# --- é…ç½®å€ ---
TOKEN = "ä½ çš„_BOT_TOKEN"
CHAT_ID = "ä½ çš„_CHAT_ID"
HISTORY_FILE = "sent_jobs_history.xlsx"  # è¨˜éŒ„å·²ç™¼é€éçš„è·ä½

def send_tg_message(text):
    """å‚³é€ HTML æ ¼å¼è¨Šæ¯è‡³ TG"""
    url = f"https://api.telegram.org/bot{TOKEN}/sendMessage"
    payload = {
        "chat_id": CHAT_ID,
        "text": text,
        "parse_mode": "HTML",
        "disable_web_page_preview": False
    }
    try:
        requests.post(url, data=payload)
    except Exception as e:
        print(f"Telegram å‚³é€å¤±æ•—: {e}")

# 1. è¼‰å…¥æ­·å²ç´€éŒ„ (ä¸­æ–·å¾Œç¹¼çºŒåŸ·è¡Œçš„é—œéµ)
if os.path.exists(HISTORY_FILE):
    df_history = pd.read_excel(HISTORY_FILE)
    # ç¢ºä¿ job_id è½‰æ›ç‚ºå­—ä¸²é›†åˆï¼Œæ–¹ä¾¿å¿«é€Ÿæ¯”å°
    sent_job_ids = set(df_history['job_id'].astype(str).tolist())
    print(f"âœ… å·²è¼‰å…¥æ­·å²ç´€éŒ„ï¼Œå…± {len(sent_job_ids)} ç­†å·²ç™¼é€è·ä½ã€‚")
else:
    df_history = pd.DataFrame()
    sent_job_ids = set()
    print("ğŸ†• æœªç™¼ç¾æ­·å²ç´€éŒ„ï¼Œå°‡å»ºç«‹æ–°æª”æ¡ˆã€‚")

# --- çˆ¬èŸ²ç²å–è³‡æ–™éƒ¨åˆ† ---
# å‡è¨­ jobs æ˜¯æ‚¨ç¶“é search_job_transform è™•ç†å¾Œçš„ list
# jobs = [job104_spider.search_job_transform(job) for job in jobs]

# 2. éæ¿¾æ‰å·²ç™¼é€éçš„è·ç¼º
new_jobs = [j for j in jobs if str(j['job_id']) not in sent_job_ids]

# 3. ç™¼é€æ–°è·ç¼ºä¸¦è¨˜éŒ„
if new_jobs:
    print(f"ç™¼ç¾ {len(new_jobs)} ç­†æ–°è·ç¼ºï¼")
    
    for job in new_jobs:
        # å»ºç«‹ç¾è§€è¨Šæ¯
        msg = (
            f"<b>ğŸ†• ç™¼ç¾æ–°è·ç¼ºï¼</b>\n"
            f"ğŸ”¹ <b>{job['name']}</b>\n"
            f"ğŸ¢ {job['company_name']}\n"
            f"ğŸ’° {job['salary']}\n"
            f"ğŸ“ {job['company_addr']}\n"
            f"ğŸ”— <a href='{job['job_url']}'>é»æˆ‘æŸ¥çœ‹è·ç¼º</a>\n"
        )
        
        # å‚³é€è‡³ Telegram
        send_tg_message(msg)
        
        # è¨˜éŒ„åˆ°å·²ç™¼é€é›†åˆä¸­
        sent_job_ids.add(str(job['job_id']))

    # 4. æ›´æ–°ä¸¦å­˜å› Excel (ä¸­æ–·å¾Œå†å›ä¾†è®€å–é€™ä»½)
    df_new = pd.DataFrame(new_jobs)
    # åˆä½µèˆŠç´€éŒ„èˆ‡æ–°ç´€éŒ„
    df_final = pd.concat([df_history, df_new], ignore_index=True)
    # ç¢ºä¿ä¸æœƒå› ç‚ºé‚è¼¯éŒ¯èª¤æœ‰é‡è¤‡
    df_final.drop_duplicates(subset=['job_id'], keep='first', inplace=True)
    
    df_final.to_excel(HISTORY_FILE, index=False)
    print(f"ğŸ’¾ å·²æ›´æ–° Excel ç´€éŒ„æª”æ¡ˆï¼š{HISTORY_FILE}")
else:
    print("ğŸ˜´ ç›®å‰æ²’æœ‰æ–°çš„è·ç¼ºéœ€è¦ç™¼é€ã€‚")





import pandas as pd
import requests
import os
from datetime import datetime

# --- é…ç½®å€ ---
TOKEN = "ä½ çš„_BOT_TOKEN"
CHAT_ID = "ä½ çš„_CHAT_ID"
HISTORY_FILE = "sent_jobs_history.xlsx"  # ç”¨ä¾†è¨˜éŒ„å·²å‚³é€éçš„è·ç¼º

def send_tg_message(text):
    """å‚³é€ HTML æ ¼å¼çš„è¨Šæ¯åˆ° Telegram"""
    url = f"https://api.telegram.org/bot{TOKEN}/sendMessage"
    payload = {
        "chat_id": CHAT_ID,
        "text": text,
        "parse_mode": "HTML",
        "disable_web_page_preview": False
    }
    try:
        response = requests.post(url, data=payload)
        return response
    except Exception as e:
        print(f"ç™¼é€ TG å¤±æ•—: {e}")

# --- è™•ç†æµç¨‹ ---

# å‡è¨­ jobs æ˜¯æ‚¨ spider è½‰æ›å¾Œçš„ list
# jobs = [job104_spider.search_job_transform(job) for job in jobs]

# 1. è®€å–æ­·å²ç´€éŒ„ (ä¸­æ–·å¾Œç¹¼çºŒåŸ·è¡Œçš„é—œéµ)
if os.path.exists(HISTORY_FILE):
    df_history = pd.read_excel(HISTORY_FILE)
    # è½‰æˆ set æé«˜æ¯”å°é€Ÿåº¦ï¼Œç¢ºä¿ job_id æ˜¯å­—ä¸²
    sent_job_ids = set(df_history['job_id'].astype(str).tolist())
    print(f"è¼‰å…¥æ­·å²ç´€éŒ„ï¼šç›®å‰å·²ç™¼é€é {len(sent_job_ids)} å€‹è·ä½")
else:
    df_history = pd.DataFrame()
    sent_job_ids = set()
    print("æœªç™¼ç¾æ­·å²ç´€éŒ„ï¼Œå°‡å»ºç«‹æ–°æª”æ¡ˆ")

# 2. è½‰æˆ DataFrame ä¸¦ç¯©é¸ã€Œä»Šå¤©ã€ä¸”ã€Œæœªå‚³é€éã€çš„è·ç¼º
df_all = pd.DataFrame(jobs)
today_str = datetime.now().strftime('%Y%m%d')

# éæ¿¾æ¢ä»¶ï¼šæ—¥æœŸæ˜¯ä»Šå¤© ä¸” job_id ä¸åœ¨å·²å‚³é€æ¸…å–®ä¸­
today_new_jobs = df_all[
    (df_all['appear_date'] == today_str) & 
    (~df_all['job_id'].astype(str).isin(sent_job_ids))
]

# 3. æ ¼å¼åŒ–è¨Šæ¯ä¸¦ç™¼é€
if not today_new_jobs.empty:
    msg = f"<b>ğŸ“… ä»Šæ—¥æ–°è·ç¼ºå¿«å ± ({today_str})</b>\n"
    msg += f"æ‰¾åˆ° {len(today_new_jobs)} ç­†æ–°æ›´æ–°ï¼š\n"
    msg += "â€”" * 10 + "\n\n"

    for _, row in today_new_jobs.iterrows():
        job_item = (
            f"ğŸ”¹ <b>{row['name']}</b>\n"
            f"ğŸ¢ å…¬å¸ï¼š{row['company_name']}\n"
            f"ğŸ’° å¾…é‡ï¼š{row['salary']}\n"
            f"ğŸ“ å­¸æ­·ï¼š{row['education']} / {row['period']}\n"
            f"ğŸ“ åœ°é»ï¼š{row['company_addr']}\n"
            f"ğŸ”— <a href='{row['job_url']}'>é»æˆ‘æŸ¥çœ‹è·ç¼ºè©³æƒ…</a>\n\n"
        )
        msg += job_item

    # å‚³é€è¨Šæ¯
    send_tg_message(msg)
    print(f"å·²ç™¼é€ {len(today_new_jobs)} ç­†æ–°è·ç¼ºè‡³ Telegramï¼")

    # 4. æ›´æ–°æ­·å²ç´€éŒ„æª”æ¡ˆ
    # å°‡é€™æ¬¡æ–°ç™¼é€çš„è·ç¼ºåˆä½µåˆ°èˆŠç´€éŒ„ä¸­
    df_updated_history = pd.concat([df_history, today_new_jobs], ignore_index=True)
    # ç§»é™¤é‡è¤‡é …ï¼ˆä¿éšªèµ·è¦‹ï¼‰
    df_updated_history.drop_duplicates(subset=['job_id'], keep='first', inplace=True)
    # å­˜å› Excel
    df_updated_history.to_excel(HISTORY_FILE, index=False)
    print(f"æ­·å²ç´€éŒ„å·²æ›´æ–°è‡³ {HISTORY_FILE}")

else:
    print(f"ğŸ“¢ {today_str} æ²’æœ‰æ–°çš„æœªå‚³é€è·ç¼ºã€‚")







































import time
import random
import requests
import pandas as pd
from datetime import datetime
import os
class Job104Spider():
    def search(self, keyword, max_mun=10, filter_params=None, sort_type='ç¬¦åˆåº¦', is_sort_asc=False):
        """æœå°‹è·ç¼º"""
        jobs = []
        total_count = 0

        url = 'https://www.104.com.tw/jobs/search/list'
        query = f'ro=0&kwop=7&keyword={keyword}&expansionType=area,spec,com,job,wf,wktm&mode=s&jobsource=2018indexpoc'
        if filter_params:
            # åŠ ä¸Šç¯©é¸åƒæ•¸ï¼Œè¦å…ˆè½‰æ›ç‚º URL åƒæ•¸å­—ä¸²æ ¼å¼
            query += ''.join([f'&{key}={value}' for key, value, in filter_params.items()])

        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.92 Safari/537.36',
            'Referer': 'https://www.104.com.tw/jobs/search/',
        }

        # åŠ ä¸Šæ’åºæ¢ä»¶
        sort_dict = {
            'ç¬¦åˆåº¦': '1',
            'æ—¥æœŸ': '2',
            'ç¶“æ­·': '3',
            'å­¸æ­·': '4',
            'æ‡‰å¾µäººæ•¸': '7',
            'å¾…é‡': '13',
        }
        sort_params = f"&order={sort_dict.get(sort_type, '1')}"
        sort_params += '&asc=1' if is_sort_asc else '&asc=0'
        query += sort_params

        page = 1
        while len(jobs) < max_mun:
            params = f'{query}&page={page}'
            r = requests.get(url, params=params, headers=headers)
            if r.status_code != requests.codes.ok:
                print('è«‹æ±‚å¤±æ•—', r.status_code)
                data = r.json()
                print(data['status'], data['statusMsg'], data['errorMsg'])
                break

            data = r.json()
            total_count = data['data']['totalCount']
            jobs.extend(data['data']['list'])

            if (page == data['data']['totalPage']) or (data['data']['totalPage'] == 0):
                break
            page += 1
            time.sleep(random.uniform(3, 5))

        return total_count, jobs[:max_mun]

    def get_job(self, job_id):
        """å–å¾—è·ç¼ºè©³ç´°è³‡æ–™"""
        url = f'https://www.104.com.tw/job/ajax/content/{job_id}'

        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.92 Safari/537.36',
            'Referer': f'https://www.104.com.tw/job/{job_id}'
        }

        r = requests.get(url, headers=headers)
        if r.status_code != requests.codes.ok:
            print('è«‹æ±‚å¤±æ•—', r.status_code)
            return

        data = r.json()
        return data['data']

    def search_job_transform(self, job_data):
        """å°‡è·ç¼ºè³‡æ–™è½‰æ›æ ¼å¼ã€è£œé½Šè³‡æ–™"""
        appear_date = job_data['appearDate']
        apply_num = int(job_data['applyCnt'])
        company_addr = f"{job_data['jobAddrNoDesc']} {job_data['jobAddress']}"

        job_url = f"https:{job_data['link']['job']}"
        job_company_url = f"https:{job_data['link']['cust']}"
        job_analyze_url = f"https:{job_data['link']['applyAnalyze']}"

        job_id = job_url.split('/job/')[-1]
        if '?' in job_id:
            job_id = job_id.split('?')[0]

        salary_high = int(job_data['salaryLow'])
        salary_low = int(job_data['salaryHigh'])

        job = {
            'job_id': job_id,
            'type': job_data['jobType'],
            'name': job_data['jobName'],  # è·ç¼ºåç¨±
            # 'desc': job_data['descSnippet'],  # æè¿°
            'appear_date': appear_date,  # æ›´æ–°æ—¥æœŸ
            'apply_num': apply_num,
            'apply_text': job_data['applyDesc'],  # æ‡‰å¾µäººæ•¸æè¿°
            'company_name': job_data['custName'],  # å…¬å¸åç¨±
            'company_addr': company_addr,  # å·¥ä½œåœ°å€
            'job_url': job_url,  # è·ç¼ºç¶²é 
            'job_analyze_url': job_analyze_url,  # æ‡‰å¾µåˆ†æç¶²é 
            'job_company_url': job_company_url,  # å…¬å¸ä»‹ç´¹ç¶²é 
            'lon': job_data['lon'],  # ç¶“åº¦
            'lat': job_data['lat'],  # ç·¯åº¦
            'education': job_data['optionEdu'],  # å­¸æ­·
            'period': job_data['periodDesc'],  # ç¶“é©—å¹´ä»½
            'salary': job_data['salaryDesc'],  # è–ªè³‡æè¿°
            'salary_high': salary_high,  # è–ªè³‡æœ€é«˜
            'salary_low': salary_low,  # è–ªè³‡æœ€ä½
            'tags': job_data['tags'],  # æ¨™ç±¤
        }
        return job


# --- é…ç½®å€ ---
TOKEN = "8528605252:AAFKh8Z_6cXKSylfDnnDWwF57KFQfe0qbbk"
CHAT_ID = "803300061"
HISTORY_FILE = "sent_jobs_history.xlsx"  # è¨˜éŒ„å·²ç™¼é€éçš„è·ä½
def send_tg_message(text):
    """å‚³é€ HTML æ ¼å¼çš„è¨Šæ¯åˆ° Telegram"""
    url = f"https://api.telegram.org/bot{TOKEN}/sendMessage"
    payload = {
        "chat_id": CHAT_ID,
        "text": text,
        "parse_mode": "HTML",
        "disable_web_page_preview": False
    }
    return requests.post(url, data=payload)


if __name__ == "__main__":
  while True:
    job104_spider = Job104Spider()

    filter_params = {
        # 'area': '6001001000,6001016000',  # (åœ°å€) å°åŒ—å¸‚,é«˜é›„å¸‚
        # 's9': '1,2,4,8',  # (ä¸Šç­æ™‚æ®µ) æ—¥ç­,å¤œç­,å¤§å¤œç­,å‡æ—¥ç­
        # 's5': '0',  # 0:ä¸éœ€è¼ªç­ 256:è¼ªç­
        # 'wktm': '1',  # (ä¼‘å‡åˆ¶åº¦) é€±ä¼‘äºŒæ—¥
        # 'isnew': '0',  # (æ›´æ–°æ—¥æœŸ) 0:æœ¬æ—¥æœ€æ–° 3:ä¸‰æ—¥å…§ 7:ä¸€é€±å…§ 14:å…©é€±å…§ 30:ä¸€å€‹æœˆå…§
        # 'jobexp': '1,3,5,10,99',  # (ç¶“æ­·è¦æ±‚) 1å¹´ä»¥ä¸‹,1-3å¹´,3-5å¹´,5-10å¹´,10å¹´ä»¥ä¸Š
        'newZone': '1',  # (ç§‘æŠ€åœ’å€) ç«¹ç§‘,ä¸­ç§‘,å—ç§‘,å…§æ¹–,å—æ¸¯
        # 'newZone': '1,2,3,4,5',  # (ç§‘æŠ€åœ’å€) ç«¹ç§‘,ä¸­ç§‘,å—ç§‘,å…§æ¹–,å—æ¸¯
        # 'zone': '16',  # (å…¬å¸é¡å‹) 16:ä¸Šå¸‚ä¸Šæ«ƒ 5:å¤–å•†ä¸€èˆ¬ 4:å¤–å•†è³‡è¨Š
        # 'wf': '1,2,3,4,5,6,7,8,9,10',  # (ç¦åˆ©åˆ¶åº¦) å¹´çµ‚çé‡‘,ä¸‰ç¯€çé‡‘,å“¡å·¥æ—…éŠ,åˆ†ç´…é…è‚¡,è¨­æ–½ç¦åˆ©,ä¼‘å‡ç¦åˆ©,æ´¥è²¼/è£œåŠ©,å½ˆæ€§ä¸Šä¸‹ç­,å¥åº·æª¢æŸ¥,åœ˜é«”ä¿éšª
        # 'edu': '1,2,3,4,5,6',  # (å­¸æ­·è¦æ±‚) é«˜ä¸­è·ä»¥ä¸‹,é«˜ä¸­è·,å°ˆç§‘,å¤§å­¸,ç¢©å£«,åšå£«
        # 'remoteWork': '1',  # (ä¸Šç­å‹æ…‹) 1:å®Œå…¨é ç«¯ 2:éƒ¨åˆ†é ç«¯
        # 'excludeJobKeyword': 'ç§‘æŠ€',  # æ’é™¤é—œéµå­—
        # 'kwop': '1',  # åªæœå°‹è·å‹™åç¨±
    }
    total_count, sent_job_ids = job104_spider.search('python', max_mun=3000, filter_params=filter_params)

    print('æœå°‹çµæœè·ç¼ºç¸½æ•¸ï¼š', total_count)
    # 1. è®€å–æ­·å²ç´€éŒ„ (ä¸­æ–·å¾Œç¹¼çºŒåŸ·è¡Œçš„é—œéµ)
    if os.path.exists(HISTORY_FILE):
        df_history = pd.read_excel(HISTORY_FILE)
        # è½‰æˆ set æé«˜æ¯”å°é€Ÿåº¦ï¼Œç¢ºä¿ job_id æ˜¯å­—ä¸²
        sent_job_ids = set(df_history['job_id'].astype(str).tolist())
        print(f"è¼‰å…¥æ­·å²ç´€éŒ„ï¼šç›®å‰å·²ç™¼é€é {len(sent_job_ids)} å€‹è·ä½")
    else:
        df_history = pd.DataFrame()
        sent_job_ids = set()
        print("æœªç™¼ç¾æ­·å²ç´€éŒ„ï¼Œå°‡å»ºç«‹æ–°æª”æ¡ˆ")

    # 2. è½‰æˆ DataFrame ä¸¦ç¯©é¸ã€Œä»Šå¤©ã€ä¸”ã€Œæœªå‚³é€éã€çš„è·ç¼º
    df_all = pd.DataFrame(jobs)
    today_str = datetime.now().strftime('%Y%m%d')

    # éæ¿¾æ¢ä»¶ï¼šæ—¥æœŸæ˜¯ä»Šå¤© ä¸” job_id ä¸åœ¨å·²å‚³é€æ¸…å–®ä¸­
    today_new_jobs = df_all[
        (df_all['appear_date'] == today_str) & 
        (~df_all['job_id'].astype(str).isin(sent_job_ids))
    ]

    # 3. æ ¼å¼åŒ–è¨Šæ¯ä¸¦ç™¼é€
    if not today_new_jobs.empty:
        msg = f"<b>ğŸ“… ä»Šæ—¥æ–°è·ç¼ºå¿«å ± ({today_str})</b>\n"
        msg += f"æ‰¾åˆ° {len(today_new_jobs)} ç­†æ–°æ›´æ–°ï¼š\n"
        msg += "â€”" * 10 + "\n\n"

        for _, row in today_new_jobs.iterrows():
            job_item = (
                f"ğŸ”¹ <b>{row['name']}</b>\n"
                f"ğŸ¢ å…¬å¸ï¼š{row['company_name']}\n"
                f"ğŸ’° å¾…é‡ï¼š{row['salary']}\n"
                f"ğŸ“ å­¸æ­·ï¼š{row['education']} / {row['period']}\n"
                f"ğŸ“ åœ°é»ï¼š{row['company_addr']}\n"
                f"ğŸ”— <a href='{row['job_url']}'>é»æˆ‘æŸ¥çœ‹è·ç¼ºè©³æƒ…</a>\n\n"
            )
            msg += job_item

        # å‚³é€è¨Šæ¯
        send_tg_message(msg)
        print(f"å·²ç™¼é€ {len(today_new_jobs)} ç­†æ–°è·ç¼ºè‡³ Telegramï¼")

        # 4. æ›´æ–°æ­·å²ç´€éŒ„æª”æ¡ˆ
        # å°‡é€™æ¬¡æ–°ç™¼é€çš„è·ç¼ºåˆä½µåˆ°èˆŠç´€éŒ„ä¸­
        df_updated_history = pd.concat([df_history, today_new_jobs], ignore_index=True)
        # ç§»é™¤é‡è¤‡é …ï¼ˆä¿éšªèµ·è¦‹ï¼‰
        df_updated_history.drop_duplicates(subset=['job_id'], keep='first', inplace=True)
        # å­˜å› Excel
        df_updated_history.to_excel(HISTORY_FILE, index=False)
        print(f"æ­·å²ç´€éŒ„å·²æ›´æ–°è‡³ {HISTORY_FILE}")

    else:
        print(f"ğŸ“¢ {today_str} æ²’æœ‰æ–°çš„æœªå‚³é€è·ç¼ºã€‚")
